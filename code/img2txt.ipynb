{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the image as a feature vector by runing it through a pre-trained InceptionV3 net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "def get_lists(anno_path):\n",
    "    with open(anno_path, 'r') as f:\n",
    "        file = json.load(f)\n",
    "    caps = file['annotations']\n",
    "    images = file['images']\n",
    "    anno_list = {item['image_id']: item['caption'] for item in caps}\n",
    "    pic_list = {item['id']: item['file_name'] for item in images}\n",
    "    return anno_list, pic_list\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = model = InceptionV3(include_top=False, input_shape= (480,640,3), pooling = 'avg')\n",
    "    anno_path = '/home/minheng/coco/annotations/annotations/captions_train2014.json'\n",
    "    anno_list, pic_list = get_lists(anno_path)\n",
    "    X = []\n",
    "    Y = []\n",
    "    path = '/home/minheng/coco/images/train2014/'\n",
    "    for key in anno_list.keys():\n",
    "        file_name = pic_list[key]\n",
    "        pic = np.expand_dims(np.array(Image.open(os.path.join(path,file_name)).resize((640,480))),axis = 0)\n",
    "        if pic.shape == (1, 480, 640, 3):\n",
    "            x = model.predict(pic)\n",
    "            X.append(x)\n",
    "            Y.append(anno_list[key])\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    np.save('coco_pre_prop_X_new', X)\n",
    "    np.save('coco_pre_prop_Y_new', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.load('coco_pre_prop_X_new.npy')\n",
    "Y = np.load('coco_pre_prop_Y_new.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2048)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A clock that blends in with the wall hangs in a bathroom. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode the label using a pre-trained word embedding model(glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# first tokenize the words, pad each caption to a fixed length with 0s. Map each caption to the embedding space. Generate a mask for the calculation of loss. In the mask, 1 means the actual word token and 0 means the padding tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from keras.layers import Embedding, Input, Dense, LSTM, RepeatVector,concatenate, Reshape,multiply\n",
    "from keras.models import Sequential, Model\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "\n",
    "def get_emb(tokenizer):\n",
    "    embeddings_index = {}\n",
    "    f = open(os.path.join('glove.6B.300d.txt'))\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "    f.close()\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    embedding_matrix = np.zeros((5000, 300))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= 5000:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            # words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def emb_model(n, embedding_matrix,y):\n",
    "    input_data = Input(shape=[n])\n",
    "    embedding_layer = Embedding(5000, 300, weights=[embedding_matrix],\n",
    "                                input_length=25, trainable=False)(input_data)\n",
    "    model = Model(input_data, embedding_layer)\n",
    "    return model.predict(y)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    Y_emb = np.load('coco_pre_prop_Y_new.npy')\n",
    "    X = np.load('coco_pre_prop_X_new.npy')\n",
    "    #X = np.reshape(X, [X.shape[0], X.shape[-1]])\n",
    "    tokenizer = Tokenizer(num_words=5000)\n",
    "    tokenizer.fit_on_texts(Y_emb)\n",
    "    sequences = tokenizer.texts_to_sequences(Y_emb)\n",
    "    data = pad_sequences(sequences, maxlen=25,truncating='post', padding='post')\n",
    "    embedding_matrix = get_emb(tokenizer)\n",
    "    Y_target = emb_model(25,embedding_matrix, data)\n",
    "    mask = Y_target.sum(axis = -1, keepdims = True) != 0\n",
    "    mask = np.repeat(mask, 300,axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use 100 samples for base case testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_lists(anno_path):\n",
    "    with open(anno_path, 'r') as f:\n",
    "        file = json.load(f)\n",
    "    caps = file['annotations']\n",
    "    images = file['images']\n",
    "    anno_list = {item['image_id']: item['caption'] for item in caps}\n",
    "    pic_list = {item['id']: item['file_name'] for item in images}\n",
    "    return anno_list, pic_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "anno_path = '/home/minheng/coco/annotations/annotations/captions_train2014.json'\n",
    "anno_list, pic_list = get_lists(anno_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_100 = []\n",
    "Y_100 = []\n",
    "path = '/home/minheng/coco/images/train2014/'\n",
    "i = 0\n",
    "for key in anno_list.keys():\n",
    "    if i <100:\n",
    "        file_name = pic_list[key]\n",
    "        pic = np.expand_dims(np.array(Image.open(os.path.join(path,file_name)).resize((320,240))),axis = 0)\n",
    "        if pic.shape == (1, 240, 320, 3):\n",
    "            X_100.append(pic)\n",
    "            Y_100.append(anno_list[key])\n",
    "            i +=1\n",
    "X_100 = np.array(X_100)\n",
    "Y_100 = np.array(Y_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use a bag of word approch to encode y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1)\n",
    "Y_tran = vectorizer.fit_transform(Y_100)\n",
    "Y_100 = Y_tran.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_100 = np.reshape(X_100, newshape = [100,240,320,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# built and base case using one dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base = Sequential()\n",
    "base.add(Flatten(input_shape = [240,320,3]))\n",
    "base.add(Dense(368, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 230400)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 368)               84787568  \n",
      "=================================================================\n",
      "Total params: 84,787,568.0\n",
      "Trainable params: 84,787,568.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 1s - loss: 104.2111 - acc: 0.0100     \n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s - loss: 115.3419 - acc: 0.0200       \n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s - loss: 115.3238 - acc: 0.0200        \n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s - loss: 115.3227 - acc: 0.0200     \n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s - loss: 115.3227 - acc: 0.0200     \n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s - loss: 115.3227 - acc: 0.0200       \n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s - loss: 115.3227 - acc: 0.0200       \n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s - loss: 115.3227 - acc: 0.0200     \n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s - loss: 115.3227 - acc: 0.0200       \n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s - loss: 115.3227 - acc: 0.0200     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ffa2f290f98>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.fit(X_100,Y_100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develope the LSTM model, this is a one to many learning. The structure of the google model is feeding the output of the current time step as input to the next time step. Due to the restriction of Keras, this approch is not possible unless I write a custom LSTM layer. So instead of the google approch, I modify the approch a little bit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_and_tell():\n",
    "    initializer = keras.initializers.RandomUniform(minval=-0.08, maxval=0.08)\n",
    "    img_fea = Input(shape=[2048], name = 'img_fea')\n",
    "    dense1 = Dense(300, kernel_initializer=initializer)(img_fea)\n",
    "    rep = RepeatVector(n=25)(dense1)\n",
    "    lstm_cell = LSTM(300, return_sequences=True,\n",
    "                kernel_initializer=initializer, dropout=0.25)(rep)\n",
    "    lstm_cell2 = LSTM(300, activation = 'softmax',return_sequences=True,\n",
    "                kernel_initializer=initializer, dropout=0.25)(lstm_cell)\n",
    "    mask_input = Input(shape = [25,300], name = 'mask_input')\n",
    "    final_output = multiply([lstm_cell2,mask_input])\n",
    "    show_and_tell = Model(inputs = [img_fea,mask_input], outputs = [final_output])\n",
    "    return show_and_tell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_and_tell = show_and_tell()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "img_fea (InputLayer)             (None, 2048)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 300)           614700                                       \n",
      "____________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)   (None, 25, 300)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                    (None, 25, 300)       721200                                       \n",
      "____________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                    (None, 25, 300)       721200                                       \n",
      "____________________________________________________________________________________________________\n",
      "mask_input (InputLayer)          (None, 25, 300)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)            (None, 25, 300)       0                                            \n",
      "====================================================================================================\n",
      "Total params: 2,057,100.0\n",
      "Trainable params: 2,057,100.0\n",
      "Non-trainable params: 0.0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "show_and_tell.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develope the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit 5 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def r2(y_true, y_pred):\n",
    "    return r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -6.3300e-05\n",
      "Epoch 2/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -3.2783e-05\n",
      "Epoch 3/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -6.1154e-05\n",
      "Epoch 4/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -4.7922e-05\n",
      "Epoch 5/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -7.7248e-05\n",
      "Epoch 6/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -8.7857e-05\n",
      "Epoch 7/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -5.7220e-06\n",
      "Epoch 8/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -2.1219e-05\n",
      "Epoch 9/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -4.9233e-05\n",
      "Epoch 10/10\n",
      "5/5 [==============================] - 0s - loss: 0.0491 - r2: -3.9577e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7469d6048>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show_and_tell = show_and_tell()\n",
    "#show_and_tell.compile(loss='mse', optimizer='sgd', metrics=[r2])\n",
    "show_and_tell.fit({'img_fea':X[:5],'mask_input':mask[:5]}, Y_target[:5],epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the whole thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_decay(epoch):\n",
    "    initial_lrate = 2\n",
    "    drop = 0.5\n",
    "    epochs_drop = 8\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    op = optimizers.SGD(lr=0.0, decay=0.0, nesterov=False)\n",
    "    show_and_tell = show_and_tell()\n",
    "    show_and_tell.compile(loss='mse', optimizer=op, metrics = [r2])\n",
    "    lrate = LearningRateScheduler(step_decay)\n",
    "    board = keras.callbacks.TensorBoard()\n",
    "    show_and_tell.fit({'img_fea':X,'mask_input':mask}, Y_target,epochs = 50,validation_split=0.3, callbacks=[lrate,board])\n",
    "    show_and_tell.save('modify8.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "show_and_tell = load_model('modify8.h5',custom_objects={'r2':r2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_mask = np.ones([1,25,300])\n",
    "\n",
    "pre = show_and_tell.predict({'img_fea':X[0],'mask_input':test_mask})\n",
    "\n",
    "pre = np.reshape(pre,newshape=[25,300])\n",
    "\n",
    "embedding_matrix.shape\n",
    "\n",
    "out = []\n",
    "for i in pre:\n",
    "    index_vect = i.dot(embedding_matrix.T)\n",
    "    out.append(np.argmax(index_vect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
